"""
å•†å“å®¡è®¡å·¥å…·
ä½¿ç”¨AIå®¡æ ¸ä»çˆ¬è™«è·å–çš„å•†å“ä¿¡æ¯ï¼ˆtitle, description, image, category, keywordï¼‰
"""

import csv
import json
import os
import sys
import traceback
from typing import Dict, List, Optional
import dashscope
from dashscope import Generation
from dotenv import load_dotenv
import pandas as pd
from datetime import datetime

# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½ï¼‰
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆai ratingç›®å½•ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)  # ä¸Šä¸€çº§ç›®å½•å°±æ˜¯ai rating
env_path = os.path.join(root_dir, '.env')
load_dotenv(env_path)


class ProductAuditor:
    """å•†å“å®¡è®¡å‘˜"""
    
    def __init__(self, api_key: str = None, model: str = "qwen-plus"):
        """åˆå§‹åŒ–å®¡è®¡å‘˜
        
        Args:
            api_key: DashScope API Key
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º qwen-plus
        """
        self.api_key = api_key or os.getenv("QWEN_API_KEY") or os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key:
            # è·å–env_pathç”¨äºé”™è¯¯æç¤º
            current_dir = os.path.dirname(os.path.abspath(__file__))
            root_dir = os.path.dirname(current_dir)
            env_path = os.path.join(root_dir, '.env')
            raise ValueError(f"API Keyæœªè®¾ç½®ï¼Œè¯·é€šè¿‡å‚æ•°ä¼ å…¥æˆ–è®¾ç½®ç¯å¢ƒå˜é‡QWEN_API_KEYæˆ–DASHSCOPE_API_KEYã€‚ç¯å¢ƒå˜é‡æ–‡ä»¶ä½ç½®: {env_path}")
        dashscope.api_key = self.api_key
        self.model = model
    
    def audit_product(self, url: str, title: str, description: str, 
                     main_image: str, image_list: str, 
                     category: str, keyword: str) -> Dict:
        """å®¡æ ¸å•ä¸ªå•†å“
        
        Args:
            url: å•†å“æºURL
            title: å•†å“æ ‡é¢˜
            description: å•†å“æè¿°
            main_image: ä¸»å›¾URL
            image_list: å…¶ä»–å›¾ç‰‡URLåˆ—è¡¨ï¼ˆJSONå­—ç¬¦ä¸²æˆ–é€—å·åˆ†éš”ï¼‰
            category: AIé¢„æµ‹çš„category
            keyword: AIé¢„æµ‹çš„keywordï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
            
        Returns:
            åŒ…å«å„é¡¹å®¡æ ¸ç»“æœçš„å­—å…¸
        """
        
        # è§£æimage_list
        image_urls = []
        if image_list:
            try:
                if image_list.startswith('[') or image_list.startswith('{'):
                    parsed = json.loads(image_list)
                    if isinstance(parsed, list):
                        image_urls = parsed
                    elif isinstance(parsed, dict):
                        image_urls = list(parsed.values())
                else:
                    # é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
                    image_urls = [img.strip() for img in image_list.split(',') if img.strip()]
            except:
                image_urls = [img.strip() for img in image_list.split(',') if img.strip()] if image_list else []
        
        # è§£ækeyword
        keyword_text = ""
        if keyword:
            try:
                if keyword.startswith('{'):
                    keyword_dict = json.loads(keyword)
                    if 'keywords_english' in keyword_dict:
                        keyword_text = ', '.join(keyword_dict['keywords_english'].values())
                    elif 'keywords' in keyword_dict:
                        keyword_text = ', '.join(keyword_dict['keywords'].values())
                    else:
                        keyword_text = str(keyword_dict)
                else:
                    keyword_text = keyword
            except:
                keyword_text = keyword
        
        # è§£æcategory
        category_text = ""
        if category:
            try:
                if category.startswith('['):
                    category_list = json.loads(category)
                    if isinstance(category_list, list) and len(category_list) > 0:
                        if 'catPath' in category_list[0]:
                            category_text = category_list[0]['catPath']
                        else:
                            category_text = str(category_list[0])
                elif category.startswith('{'):
                    category_dict = json.loads(category)
                    if 'catPath' in category_dict:
                        category_text = category_dict['catPath']
                    else:
                        category_text = str(category_dict)
                else:
                    category_text = category
            except:
                category_text = category
        
        # æ£€æŸ¥categoryæ˜¯å¦ä¸ºç©ºæˆ–N/Aï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥æ ‡è®°ä¸ºNEEDS_MANUAL_CHECK
        category_is_empty_or_na = False
        if not category_text:
            category_is_empty_or_na = True
        else:
            category_text_trimmed = category_text.strip()
            if not category_text_trimmed:
                category_is_empty_or_na = True
            elif category_text_trimmed.upper() in ['N/A', 'NA', 'NULL', 'NONE']:
                category_is_empty_or_na = True
        
        # æ„å»ºå®¡æ ¸prompt
        prompt = f"""You are an AI product auditor. Please review the following product information scraped from a website and imported to a new platform.

**Product Source URL:** {url}

**Product Information to Review:**

0. **Product URL** (scraped URL):
{url if url else "N/A"}

1. **Title** (scraped from source website):
{title if title else "N/A"}

2. **Description** (scraped from source website):
{description if description else "N/A"}

3. **AI Predicted Category:**
{category_text if category_text else "N/A"}

4. **AI Predicted Keywords:**
{keyword_text if keyword_text else "N/A"}

**Review Criteria:**

For each aspect (URL, Title, Description, Category, Keyword), please evaluate:
Note: Image review is currently skipped.

**URL Review:**
- Is the URL a valid product page URL?
- Does the URL structure indicate it's a product page (not a category page, homepage, or other non-product page)?
- **IMPORTANT**: Check if the URL is a company success case/portfolio page (e.g., contains "case", "portfolio", "success", "project", "client", "example", "story", etc.). If it's a success case page, it is NOT a product URL and should be marked as NEEDS_MANUAL_CHECK.
- **IMPORTANT**: Check if the URL is a category page or multi-product listing page (e.g., contains "category", "catalog", "products", "list", "collection", "browse", "shop", "all", or shows multiple products). If it's a category/multi-product page, mark as NEEDS_REVIEW and specify "Category page" or "Multi-product page" in the reason (this will be highlighted in yellow).
- Are there any other signs that this is not a product URL (e.g., contains "search", "home", "about", "contact", etc.)?
- **Decision Rules:**
  - If the URL is clearly a valid single product page and is NOT a success case page â†’ mark as PASS
  - If the URL is a success case page â†’ mark as NEEDS_MANUAL_CHECK
  - If the URL is a category page or multi-product listing page â†’ mark as NEEDS_REVIEW with reason "Category page" or "Multi-product page" (this will be highlighted in yellow)
  - If you are uncertain or unclear whether it's a product URL â†’ mark as NEEDS_REVIEW (this will be highlighted in yellow)

**Title Review:**
Since the title is directly scraped from the source website without AI processing, please check:
- Does the scraped title match the product name/identifier in the source URL?
- Is the title consistent with what would be expected from the URL structure?
- If the URL contains product identifiers or names, do they match the scraped title?
- If there's a mismatch or inconsistency, mark as NEEDS_REVIEW or NEEDS_MANUAL_CHECK accordingly.

**Description Review:**
Since the description is directly scraped from the source website without AI processing, please check:
- Does the scraped description match/relate to the product name in the URL?
- Is the description consistent with the product title?
- Does the description content align with what would be expected for this product based on the URL?
- If there's a mismatch or inconsistency, mark as NEEDS_REVIEW or NEEDS_MANUAL_CHECK accordingly.

**Category Review:**
- Is the AI-predicted category accurate and appropriate?
- Does it match the product type?
- Is the category path logical?
- Are there any issues (wrong category, too broad, too narrow)?

**Keyword Review:**
Since keywords are limited to a maximum of 3, the review criteria is simplified:
- Do the keywords match/describe the product? If yes, then PASS.
- If keywords are irrelevant or don't match the product description, then mark as NEEDS_REVIEW or NEEDS_MANUAL_CHECK based on severity.

**Output Format:**
Please provide your review in the following JSON format:
{{
    "url_review": {{
        "status": "PASS" | "NEEDS_REVIEW" | "NEEDS_MANUAL_CHECK",
        "reason": "Brief explanation of the review decision"
    }},
    "title_review": {{
        "status": "PASS" | "NEEDS_REVIEW" | "NEEDS_MANUAL_CHECK",
        "reason": "Brief explanation of the review decision"
    }},
    "description_review": {{
        "status": "PASS" | "NEEDS_REVIEW" | "NEEDS_MANUAL_CHECK",
        "reason": "Brief explanation of the review decision"
    }},
    "category_review": {{
        "status": "PASS" | "NEEDS_REVIEW" | "NEEDS_MANUAL_CHECK",
        "reason": "Brief explanation of the review decision"
    }},
    "keyword_review": {{
        "status": "PASS" | "NEEDS_REVIEW" | "NEEDS_MANUAL_CHECK",
        "reason": "Brief explanation of the review decision"
    }}
}}

**Status Definitions:**
- "PASS" (é€šè¿‡): The content is acceptable and can be used directly (will be highlighted in green)
  - For Keywords: If keywords match/describe the product, mark as PASS
  - For URL: If the URL is clearly a valid product page
- "NEEDS_REVIEW" (éœ€è¦æŠ½æŸ¥): The content has minor issues, is uncertain, or needs spot-checking (will be highlighted in yellow)
  - For Keywords: If some keywords are slightly irrelevant but mostly acceptable
  - For URL: 
    - If you are uncertain whether the URL is a valid product page
    - If the URL is a category page or multi-product listing page (mark as NEEDS_REVIEW with reason "Category page" or "Multi-product page")
  - For Title/Description: If there's slight inconsistency but mostly acceptable
- "NEEDS_MANUAL_CHECK" (éœ€è¦äººå·¥å¤æ ¸): The content has significant issues and requires manual review (will be highlighted in red)
  - For Keywords: If keywords are completely irrelevant or don't match the product at all
  - For URL: If the URL is clearly NOT a product page (e.g., success case page, category page, etc.)
  - For Title/Description: If there's significant inconsistency or mismatch

**Important:** Please respond ONLY with valid JSON, no additional text or explanations before or after the JSON.

Please provide your review in JSON format only, no additional text."""

        messages = [
            {
                "role": "system",
                "content": "You are a professional product quality auditor. You review scraped product information for consistency with the source website. The title and description are directly scraped from the source website without AI processing, so you should focus on checking consistency between the URL, title, and description. Always respond in valid JSON format."
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        try:
            response = Generation.call(
                model=self.model,
                messages=messages,
                temperature=0.3,
                result_format='message'
            )
            
            if response.status_code == 200:
                # è§£æå“åº”
                content = ""
                if hasattr(response, 'output') and response.output is not None:
                    if hasattr(response.output, 'choices') and response.output.choices:
                        if len(response.output.choices) > 0:
                            choice = response.output.choices[0]
                            if hasattr(choice, 'message') and choice.message is not None:
                                if hasattr(choice.message, 'content'):
                                    content = choice.message.content.strip()
                    elif hasattr(response.output, 'text') and response.output.text:
                        content = response.output.text.strip()
                
                if not content:
                    raise ValueError("APIå“åº”ä¸ºç©º")
                
                # æå–JSONï¼ˆå¯èƒ½åŒ…å«markdownä»£ç å—ï¼‰
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                # è§£æJSON
                try:
                    review_result = json.loads(content)
                    # ç¡®ä¿ä¸åŒ…å«image_reviewï¼ˆå·²è·³è¿‡ï¼‰
                    if 'image_review' in review_result:
                        del review_result['image_review']
                    # ç¡®ä¿åŒ…å«url_review
                    if 'url_review' not in review_result:
                        review_result['url_review'] = {"status": "NEEDS_MANUAL_CHECK", "reason": "URLå®¡æ ¸ç»“æœç¼ºå¤±"}
                    # å¦‚æœcategoryä¸ºç©ºæˆ–N/Aï¼Œç›´æ¥æ ‡è®°ä¸ºNEEDS_MANUAL_CHECK
                    if category_is_empty_or_na:
                        review_result['category_review'] = {"status": "NEEDS_MANUAL_CHECK", "reason": "Categoryä¸ºç©ºæˆ–N/A"}
                    return review_result
                except json.JSONDecodeError as e:
                    print(f"JSONè§£æå¤±è´¥ï¼Œå“åº”å†…å®¹å‰500å­—ç¬¦: {content[:500]}")
                    print(f"JSONè§£æé”™è¯¯: {e}")
                    traceback.print_exc()
                    # è¿”å›é»˜è®¤ç»“æœ
                    return self._get_default_review("JSONè§£æå¤±è´¥")
            else:
                error_msg = getattr(response, 'message', 'æœªçŸ¥é”™è¯¯')
                print(f"APIè°ƒç”¨å¤±è´¥ (çŠ¶æ€ç : {response.status_code}): {error_msg}")
                return self._get_default_review(f"APIè°ƒç”¨å¤±è´¥: {error_msg}")
                
        except Exception as e:
            print(f"å®¡æ ¸è¿‡ç¨‹å‡ºé”™: {e}")
            traceback.print_exc()
            return self._get_default_review(f"å®¡æ ¸å‡ºé”™: {str(e)}")
    
    def _get_default_review(self, error_msg: str) -> Dict:
        """è¿”å›é»˜è®¤å®¡æ ¸ç»“æœï¼ˆå½“å‡ºé”™æ—¶ï¼‰"""
        default_status = "NEEDS_MANUAL_CHECK"
        return {
            "url_review": {"status": default_status, "reason": error_msg},
            "title_review": {"status": default_status, "reason": error_msg},
            "description_review": {"status": default_status, "reason": error_msg},
            "image_review": {"status": "SKIP", "reason": "Imageå®¡æ ¸å·²è·³è¿‡"},
            "category_review": {"status": default_status, "reason": error_msg},
            "keyword_review": {"status": default_status, "reason": error_msg}
        }
    
    def audit_from_csv(self, input_file: str, output_file: str = None):
        """ä»CSVæ–‡ä»¶è¯»å–å¹¶å®¡æ ¸å•†å“"""
        
        # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆscraperç›®å½•ï¼‰
        current_dir = os.path.dirname(os.path.abspath(__file__))
        report_dir = os.path.join(current_dir, "report")
        os.makedirs(report_dir, exist_ok=True)
        
        if output_file is None:
            # é»˜è®¤ä¿å­˜åˆ°reportæ–‡ä»¶å¤¹
            base_name = os.path.basename(input_file).replace(".csv", "")
            output_file = os.path.join(report_dir, f"{base_name}_audit_result.xlsx")
        else:
            # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œç¡®ä¿ä¿å­˜åˆ°reportæ–‡ä»¶å¤¹
            if not os.path.isabs(output_file):
                # ç›¸å¯¹è·¯å¾„ï¼Œä¿å­˜åˆ°reportæ–‡ä»¶å¤¹
                if not output_file.startswith("report/"):
                    output_file = os.path.join(report_dir, output_file)
                else:
                    output_file = os.path.join(current_dir, output_file)
        
        results = []
        
        # è¯»å–CSVæ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            total_rows = sum(1 for _ in open(input_file, 'r', encoding='utf-8-sig')) - 1  # å‡å»header
            
            for idx, row in enumerate(reader, 1):
                url = row.get('url', '')
                title = row.get('title', '')
                description = row.get('description', '')
                main_image = row.get('product_main_image', '')
                image_list = row.get('product_image_list', '')
                category = row.get('cate_info_ai', '')
                keyword = row.get('keyword_ai', '')
                
                print(f"\n[{idx}/{total_rows}] å®¡æ ¸å•†å“: {title[:50]}...")
                print(f"  URL: {url}")
                
                # æ‰§è¡Œå®¡æ ¸
                review_result = self.audit_product(
                    url=url,
                    title=title,
                    description=description,
                    main_image=main_image,
                    image_list=image_list,
                    category=category,
                    keyword=keyword
                )
                
                # æ„å»ºç»“æœè¡Œï¼ˆæŒ‰ç…§ç”¨æˆ·è¦æ±‚ï¼šåŒ…å«titleå’Œå„ç±»åˆ¤å®šç»“æœï¼‰
                # æ³¨æ„ï¼šimageå®¡æ ¸å·²è·³è¿‡
                result_row = {
                    'id': row.get('id', ''),
                    'url': url,
                    'title': title,
                    'url_åˆ¤å®šç»“æœ': review_result.get('url_review', {}).get('status', 'NEEDS_MANUAL_CHECK'),
                    'url_åˆ¤å®šåŸå› ': review_result.get('url_review', {}).get('reason', ''),
                    'title_åˆ¤å®šç»“æœ': review_result.get('title_review', {}).get('status', 'NEEDS_MANUAL_CHECK'),
                    'title_åˆ¤å®šåŸå› ': review_result.get('title_review', {}).get('reason', ''),
                    'description_åˆ¤å®šç»“æœ': review_result.get('description_review', {}).get('status', 'NEEDS_MANUAL_CHECK'),
                    'description_åˆ¤å®šåŸå› ': review_result.get('description_review', {}).get('reason', ''),
                    'category_åˆ¤å®šç»“æœ': review_result.get('category_review', {}).get('status', 'NEEDS_MANUAL_CHECK'),
                    'category_åˆ¤å®šåŸå› ': review_result.get('category_review', {}).get('reason', ''),
                    'keyword_åˆ¤å®šç»“æœ': review_result.get('keyword_review', {}).get('status', 'NEEDS_MANUAL_CHECK'),
                    'keyword_åˆ¤å®šåŸå› ': review_result.get('keyword_review', {}).get('reason', ''),
                }
                
                results.append(result_row)
                
                # æ‰“å°ç®€è¦ç»“æœ
                print(f"  ç»“æœ: URL={result_row['url_åˆ¤å®šç»“æœ']}, Title={result_row['title_åˆ¤å®šç»“æœ']}, Description={result_row['description_åˆ¤å®šç»“æœ']}, "
                      f"Category={result_row['category_åˆ¤å®šç»“æœ']}, Keyword={result_row['keyword_åˆ¤å®šç»“æœ']}")
        
        # ä¿å­˜ä¸ºExcelå¹¶æ·»åŠ é¢œè‰²æ ¼å¼åŒ–
        if results:
            df = pd.DataFrame(results)
            df.to_excel(output_file, index=False, engine='openpyxl')
            
            # æ·»åŠ é¢œè‰²æ ¼å¼åŒ–
            from openpyxl import load_workbook
            from openpyxl.styles import PatternFill
            
            wb = load_workbook(output_file)
            ws = wb.active
            
            # å®šä¹‰é¢œè‰²
            green_fill = PatternFill(start_color="90EE90", end_color="90EE90", fill_type="solid")  # æµ…ç»¿è‰²
            yellow_fill = PatternFill(start_color="FFFF99", end_color="FFFF99", fill_type="solid")  # é»„è‰²
            red_fill = PatternFill(start_color="FF6B6B", end_color="FF6B6B", fill_type="solid")  # çº¢è‰²
            
            # æ‰¾åˆ°åˆ¤å®šç»“æœåˆ—çš„ç´¢å¼•
            header_row = 1
            status_columns = {}
            for col_idx, cell in enumerate(ws[header_row], 1):
                if cell.value and 'åˆ¤å®šç»“æœ' in str(cell.value):
                    status_columns[col_idx] = cell.value
            
            # ä¸ºåˆ¤å®šç»“æœå•å…ƒæ ¼ç€è‰²
            for row_idx in range(2, len(results) + 2):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡headerï¼‰
                for col_idx, col_name in status_columns.items():
                    cell = ws.cell(row=row_idx, column=col_idx)
                    status = str(cell.value).upper()
                    
                    if status == "PASS":
                        cell.fill = green_fill
                    elif status == "NEEDS_REVIEW":
                        cell.fill = yellow_fill
                    elif status == "NEEDS_MANUAL_CHECK":
                        cell.fill = red_fill
            
            # ä¿å­˜æ ¼å¼åŒ–åçš„Excel
            wb.save(output_file)
            
            print(f"\nâœ… å®¡æ ¸å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            print(f"å…±å®¡æ ¸ {len(results)} ä¸ªå•†å“")
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            for col in ['title_åˆ¤å®šç»“æœ', 'description_åˆ¤å®šç»“æœ', 'category_åˆ¤å®šç»“æœ', 'keyword_åˆ¤å®šç»“æœ']:
                if col in df.columns:
                    status_counts = df[col].value_counts()
                    print(f"\n{col}:")
                    for status, count in status_counts.items():
                        percentage = (count / len(df)) * 100
                        print(f"  {status}: {count} ({percentage:.1f}%)")
        else:
            print("âš ï¸ æ²¡æœ‰å®¡æ ¸ç»“æœå¯ä¿å­˜")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å•†å“å®¡è®¡å·¥å…·')
    parser.add_argument('input_file', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚: database/dema.csvï¼‰')
    parser.add_argument('-o', '--output', help='è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶å_audit_result.xlsxï¼‰')
    parser.add_argument('--api-key', help='Qwen/DashScope API Keyï¼ˆå¯é€‰ï¼Œä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡QWEN_API_KEYæˆ–DASHSCOPE_API_KEYè®¾ç½®ï¼‰')
    parser.add_argument('--model', default='qwen-plus', help='ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤: qwen-plusï¼Œå¯é€‰: qwen-turbo, qwen-maxç­‰ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥API Key
    api_key = args.api_key or os.getenv("QWEN_API_KEY") or os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        root_dir = os.path.dirname(current_dir)
        env_path = os.path.join(root_dir, '.env')
        print(f"é”™è¯¯: è¯·è®¾ç½®QWEN_API_KEYæˆ–DASHSCOPE_API_KEYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--api-keyå‚æ•°")
        print(f"æç¤º: ç¯å¢ƒå˜é‡æ–‡ä»¶ä½ç½®: {env_path}")
        return
    
    # åˆ›å»ºå®¡è®¡å‘˜å¹¶æ‰§è¡Œå®¡æ ¸
    auditor = ProductAuditor(api_key=api_key, model=args.model)
    auditor.audit_from_csv(args.input_file, args.output)


if __name__ == "__main__":
    main()

